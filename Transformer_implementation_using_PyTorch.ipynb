{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b82c9948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3950e333",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the dimension of all intermediate outputs in the model\n",
    "d_model = 512\n",
    "#the number of attention heads\n",
    "h = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdfdf397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(array):\n",
    "    \"\"\"\n",
    "    Applies softmax function along the rows of the array of dimension (N, n, m), N is the batch size\n",
    "    Args:\n",
    "        array (torch.Tensor): torch.Tensor with dimension (N, n, m), N is the batch size\n",
    "    Returns:\n",
    "        torch.Tensor: Output tensor of dimension (N, n, m), N is the batch size\n",
    "    \"\"\"\n",
    "    #print(\"softmax Inp: \", array.shape)\n",
    "    expand_dim = array.shape[-1]    \n",
    "    deno = torch.sum(torch.exp(array), axis=2)[:,None].permute(0, 2, 1).expand(-1,-1,expand_dim)\n",
    "    #print(\"softmax out: \", (torch.exp(array)/deno).shape)\n",
    "    return torch.exp(array)/deno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35287203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(outputs, labels):\n",
    "    \"\"\"\n",
    "    Computes accuracy of the model output against the ground truth labels\n",
    "    Args:\n",
    "        outputs (torch.Tensor): model outputs of dimension (N, sequence_length, self.target_vocab)\n",
    "        labels (torch.Tensor): ground truth labels of dimension (N, sequence_length)\n",
    "    Returns:\n",
    "        torch.tensor: accuracy\n",
    "    \"\"\"\n",
    "    #print(\"get_accuracy inp: \", outputs.shape)\n",
    "    #print(\"get_accuracy inp: \", labels.shape)\n",
    "    _, preds = torch.max(outputs, dim=2)\n",
    "    #print(\"get_accuracy inp: \", (torch.tensor(torch.sum(preds == labels).item() / preds.numel())).shape)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / preds.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2b2792b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_head_attention(query, key, value, apply_mask=False, mask=None):\n",
    "    \"\"\"\n",
    "    Perform forward single head attention operation on the given queries, keys and values\n",
    "    Args:\n",
    "        query (torch.Tensor): torch.Tensor with dimension (N, sequence_length, d_model//h), where h is the no of heads and N is batch size\n",
    "        key (torch.Tensor): torch.Tensor with dimension (N, sequence_length, d_model//h), where h is the no of heads and N is batch size\n",
    "        value (torch.Tensor): torch.Tensor with dimension (N, sequence_length, d_model//h), where h is the no of heads and N is batch size\n",
    "    Returns:\n",
    "        torch.Tensor: torch.Tensor with dimension (N, sequence_length, d_model//h), where h is the no of heads and N is batch size\n",
    "    \"\"\"\n",
    "    #print(\"SHA inp shape: \", query.shape)\n",
    "    d_k = key.shape[2]\n",
    "    out = torch.matmul(query, key.permute(0, 2, 1))/np.power(d_k, 0.5)\n",
    "    if apply_mask:\n",
    "        tmp = mask==0\n",
    "        minus_inf = torch.from_numpy(np.ones((mask.shape[0], mask.shape[1]))*np.NINF)\n",
    "        tmp = tmp*minus_inf\n",
    "        #setting Nan values to 0\n",
    "        tmp[tmp != tmp] = 0\n",
    "        out = out*mask + tmp\n",
    "    #print(\"SHA out shape: \", torch.matmul(softmax(out), value).shape)\n",
    "    return torch.matmul(softmax(out), value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c30a672",
   "metadata": {},
   "outputs": [],
   "source": [
    "class multi_head_attention(nn.Module):\n",
    "    \"\"\"\n",
    "    Performs multi head attention\n",
    "    Attributes:\n",
    "        head_count (positive integer): #the number of attention heads\n",
    "        d_model (positive integer): #the output dimension of all sub-layers in the model\n",
    "        d_k (positive integer): #the dimension of keys and queries\n",
    "        d_v (positive integer): #the dimension of values\n",
    "        W_heads (dict): dictionary of dictionaries for each head, containing weight matrices of queries, keys and values\n",
    "                        index by \"Q\", \"K\" and \"V\" respectively\n",
    "        W_concat (dict): weight matrix of dimension (head_count*d_v, d_model)\n",
    "    Methods:\n",
    "        forward(self, queries, keys, values, apply_mask=False, mask=None)\n",
    "            Perform forward multi head attention operation on the given queries, keys and values\n",
    "    \"\"\"\n",
    "    def __init__(self, n_heads, d_model):\n",
    "        super().__init__()\n",
    "        self.head_count = n_heads\n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_model//self.head_count\n",
    "        self.d_v = d_model//self.head_count\n",
    "        self.W_heads = dict()\n",
    "        for i in range(self.head_count):\n",
    "            self.W_heads[i] = dict()\n",
    "            self.W_heads[i][\"Q\"] = nn.Linear(self.d_model, self.d_k).double()\n",
    "            self.W_heads[i][\"K\"] = nn.Linear(self.d_model, self.d_k).double()\n",
    "            self.W_heads[i][\"V\"] = nn.Linear(self.d_model, self.d_v).double()\n",
    "        self.W_concat = nn.Linear(self.head_count*self.d_v, self.d_model).double()\n",
    "    \n",
    "    def forward(self, queries, keys, values, apply_mask=False, mask=None):\n",
    "        \"\"\"\n",
    "        Perform forward multi head attention operation on the given queries, keys and values\n",
    "        Args:\n",
    "            queries (torch.Tensor): torch.Tensor with dimension (N, sequence_length, self.d_model), where N is batch size\n",
    "            keys (torch.Tensor): torch.Tensor with dimension (N, sequence_length, self.d_model), where N is batch size\n",
    "            values (torch.Tensor): torch.Tensor with dimension (N, sequence_length, self.d_model), where N is batch size\n",
    "        Returns:\n",
    "            torch.Tensor: torch.Tensor with dimension (N, sequence_length, self.d_model), where N is batch size\n",
    "        \"\"\"\n",
    "        #print(\"MHA inp shape: \", queries.shape)\n",
    "        concat_heads = torch.zeros(queries.shape)\n",
    "        concat_heads = concat_heads.to(torch.double)\n",
    "        for i in range(self.head_count):\n",
    "            query = self.W_heads[i][\"Q\"](queries)\n",
    "            key = self.W_heads[i][\"K\"](keys)\n",
    "            value = self.W_heads[i][\"V\"](values)\n",
    "            head = single_head_attention(query, key, value, apply_mask, mask)\n",
    "            concat_heads[:, :, i*self.d_v : (i+1)*self.d_v ] = head\n",
    "        #print(\"MHA out shape: \", self.W_concat(concat_heads).shape)\n",
    "        return self.W_concat(concat_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f1e53f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelBase(nn.Module):\n",
    "    \"\"\"\n",
    "    Class containing basic methods that are required for training the model\n",
    "    Methods:\n",
    "        training_step(batch)\n",
    "            Computes the output for inputs within the batch and return the loss and accuracy on these inputs\n",
    "        testing_step (batch)\n",
    "            Computes the output for inputs within the batch and return the loss and accuracy on these inputs\n",
    "        training_epoch_stats(batch_stats)\n",
    "            Computes the mean of the training batch statistics after each epoch\n",
    "        testing_epoch_stats(batch_stats)\n",
    "            Computes the mean of the test batch statistics after each epoch\n",
    "    \"\"\"\n",
    "    def training_step(self, batch):\n",
    "        \"\"\"\n",
    "        Computes the output for inputs within the batch and return the loss and accuracy on these inputs\n",
    "        Args:\n",
    "            batch (object of class DataGenerator): Contains source data, target input data, target output data and target mask\n",
    "        Returns:\n",
    "            dict: a dict containing loss and accuracy\n",
    "        \"\"\"\n",
    "        out = self.forward(batch)\n",
    "        loss = F.cross_entropy(out.permute(0,2,1), batch.data_tgt_op.to(torch.long))\n",
    "        with torch.no_grad():\n",
    "            accuracy = get_accuracy(out, batch.data_tgt_op)\n",
    "        return {'train_loss': loss, 'train_accuracy': accuracy}\n",
    "    \n",
    "    def testing_step(self, batch):\n",
    "        \"\"\"\n",
    "        Computes the output for inputs within the batch and return the loss and accuracy on these inputs\n",
    "        Args:\n",
    "            batch (object of class DataGenerator): Contains source data, target input data, target output data and target mask\n",
    "        Returns:\n",
    "            dict: a dict containing loss and accuracy\n",
    "        \"\"\"\n",
    "        out = self.forward(batch)\n",
    "        loss = F.cross_entropy(out.permute(0,2,1), batch.data_tgt_op.to(torch.long))\n",
    "        with torch.no_grad():\n",
    "            accuracy = get_accuracy(out, batch.data_tgt_op)\n",
    "        return {'test_loss': loss.detach(), 'test_accuracy': accuracy}\n",
    "        \n",
    "    def training_epoch_stats(self, batch_stats):\n",
    "        \"\"\"\n",
    "        Computes the mean of the training batch statistics after each epoch\n",
    "        Args:\n",
    "            batch_stats (list): list containing dicts, one for each batch (which are outputs of training_step)\n",
    "        Returns:\n",
    "            dict: a dict containing loss and accuracy\n",
    "        \"\"\"\n",
    "        n_batches = len(batch_stats)\n",
    "        epoch_train_loss = sum([x['train_loss'].item() for x in batch_stats])/n_batches\n",
    "        epoch_train_accuracy = sum([x['train_accuracy'].item() for x in batch_stats])/n_batches\n",
    "        return {'train_loss': epoch_train_loss, 'train_accuracy': epoch_train_accuracy}    \n",
    "    \n",
    "    def testing_epoch_stats(self, batch_stats):\n",
    "        \"\"\"\n",
    "        Computes the mean of the test batch statistics after each epoch\n",
    "        Args:\n",
    "            batch_stats (list): list containing dicts, one for each batch (which are outputs of testing_step)\n",
    "        Returns:\n",
    "            dict: a dict containing loss and accuracy\n",
    "        \"\"\"\n",
    "        n_batches = len(batch_stats)\n",
    "        epoch_test_loss = sum([x['test_loss'].item() for x in batch_stats])/n_batches\n",
    "        epoch_test_accuracy = sum([x['test_accuracy'].item() for x in batch_stats])/n_batches\n",
    "        return {'test_loss': epoch_test_loss, 'test_accuracy': epoch_test_accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bb51f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFN(nn.Module):\n",
    "    \"Implements FFN equation\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.W1 = nn.Linear(d_model, 2048).double()\n",
    "        self.W2 = nn.Linear(2048, d_model).double()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Argument:\n",
    "            x (torch.tensor): of dimension (N, sequence_length, d_model)\n",
    "        Returns:\n",
    "            torch.tensor: of dimension (N, sequence_length, d_model)\n",
    "        \"\"\"\n",
    "        #print(\"FFN inp: \", x.shape)\n",
    "        out = self.W1(x)\n",
    "        out = F.relu(out)\n",
    "        out = self.W2(out)\n",
    "        #print(\"FFN out: \", out.shape)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42c1625b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder_layer(nn.Module):\n",
    "    \"\"\"\n",
    "    contains functionality of one encoder block\n",
    "    \"\"\"\n",
    "    def __init__(self, dropout_prob=0.1):\n",
    "        super().__init__()\n",
    "        self.multi_head_att = multi_head_attention(h, d_model)\n",
    "        self.ffn = FFN()\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        forward pass in the encoder layer\n",
    "        Argument:\n",
    "            x (torch.tensor): of dimension (N, self.seq_len, d_model)\n",
    "        Returns:\n",
    "            torch.tensor: of dimension (N, self.seq_len, d_model)\n",
    "        \"\"\"\n",
    "        #print(\"Encoder inp: \", x.shape)\n",
    "        x = x.to(torch.double)\n",
    "        out = self.multi_head_att.forward(x, x, x)\n",
    "        out = self.dropout(out)\n",
    "        out = out + nn.LayerNorm([out.shape[1], out.shape[2]]).double()(out)\n",
    "        \n",
    "        out = self.ffn(out)\n",
    "        out = self.dropout(out)\n",
    "        out = out + nn.LayerNorm([out.shape[1], out.shape[2]]).double()(out)\n",
    "        #print(\"Encoder out: \", out.shape)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5988393",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder_layer(nn.Module):\n",
    "    \"\"\"\n",
    "    contains functionality of one encoder block\n",
    "    \"\"\"\n",
    "    def __init__(self, dropout_prob=0.1):\n",
    "        super().__init__()\n",
    "        self.multi_head_att = multi_head_attention(h, d_model)\n",
    "        self.ffn = FFN()\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        \n",
    "    def forward(self, dec_x, enc_x, apply_mask=False, dec_x_msk=None):\n",
    "        \"\"\"\n",
    "        forward pass in the encoder layer\n",
    "        Argument:\n",
    "            dec_x (torch.tensor): of dimension (N, target_sequence_length-1, d_model)\n",
    "            enc_x (torch.tensor): of dimension (N, source_sequence_length, d_model)\n",
    "            apply_mask (bool): apply mask if True \n",
    "            dec_x_msk: torch.tensor of dimension (target_sequence_length-1, target_sequence_length-1) if apply_mask\n",
    "        Returns:\n",
    "            torch.tensor: of dimension (N, target_sequence_length-1, d_model)\n",
    "        \"\"\"\n",
    "        #print(\"Decoder inp1: \", dec_x.shape)\n",
    "        #print(\"Decoder inp2: \", enc_x.shape)\n",
    "        #if apply_mask:\n",
    "            #print(\"Decoder inp3: \", dec_x_msk.shape)\n",
    "        dec_x = dec_x.to(torch.double)\n",
    "        enc_x = enc_x.to(torch.double)\n",
    "        out = self.multi_head_att.forward(dec_x, dec_x, dec_x, apply_mask, dec_x_msk)\n",
    "        out = self.dropout(out)\n",
    "        out = out + nn.LayerNorm([out.shape[1], out.shape[2]]).double()(out)\n",
    "        \n",
    "        out = self.multi_head_att.forward(dec_x, enc_x, enc_x)\n",
    "        out = self.dropout(out)\n",
    "        out = out + nn.LayerNorm([out.shape[1], out.shape[2]]).double()(out)\n",
    "        \n",
    "        out = self.ffn(out)\n",
    "        out = self.dropout(out)\n",
    "        out = out + nn.LayerNorm([out.shape[1], out.shape[2]]).double()(out)\n",
    "        #print(\"Decoder out: \", out.shape)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69ed057d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, dim1, dim2):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(dim1, dim2).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ae2b7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positionalEncoding(n_pos):\n",
    "    \"\"\"\n",
    "    positional encoding\n",
    "    Attributes:\n",
    "        n_pos (positive integer): #positions\n",
    "    Returns:\n",
    "        np.array: of dimension (n_pos, d_model)\n",
    "    \"\"\"\n",
    "    temp1 = []\n",
    "    for i in range(n_pos):\n",
    "        temp2 = []\n",
    "        for j in range(d_model):\n",
    "            temp2.append(i / np.power(10000, 2 * (j // 2) / d_model))\n",
    "        temp1.append(np.array(temp2))\n",
    "    PE = np.array(temp1)\n",
    "    PE[:, 0::2] = np.sin(PE[:, 0::2])\n",
    "    PE[:, 1::2] = np.cos(PE[:, 1::2])\n",
    "    #print(\"PE: \", PE.shape)\n",
    "    return PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5518369f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(ModelBase):\n",
    "    \"\"\"\n",
    "    Implementation of transformer using PyTorch\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, seq_len, dropout_prob=0.1):\n",
    "        super().__init__()\n",
    "        #to include start and end tokens\n",
    "        self.source_vocab = vocab_size + 2\n",
    "        self.target_vocab = vocab_size + 2\n",
    "        self.seq_len = seq_len + 2\n",
    "        self.source_embed = Embeddings(d_model, self.source_vocab)\n",
    "        self.target_embed = Embeddings(d_model, self.target_vocab)\n",
    "        self.encoder1 = Encoder_layer()\n",
    "        self.encoder2 = Encoder_layer()\n",
    "        self.encoder3 = Encoder_layer()\n",
    "        self.encoder4 = Encoder_layer()\n",
    "        self.encoder5 = Encoder_layer()\n",
    "        self.encoder6 = Encoder_layer()\n",
    "        self.decoder1 = Decoder_layer()\n",
    "        self.decoder2 = Decoder_layer()\n",
    "        self.decoder3 = Decoder_layer()\n",
    "        self.decoder4 = Decoder_layer()\n",
    "        self.decoder5 = Decoder_layer()\n",
    "        self.decoder6 = Decoder_layer()\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Perform forward operation from input to output, in Transformer\n",
    "        Args:\n",
    "            x (object of class DataGenerator): Contains source data, target input data, target output data and target mask\n",
    "        Returns:\n",
    "            torch.tensor: of dimension (N, target_sequence_len-1, self.vocab_size)\n",
    "        \"\"\"\n",
    "        self.tgt_msk = x.data_tgt_msk\n",
    "        \n",
    "        self.src_query = torch.from_numpy(np.zeros((x.data_src.shape[0], x.data_src.shape[1], d_model)))\n",
    "        source_map = self.source_embed.embed.weight.clone()\n",
    "        #source embedding\n",
    "        for batch_idx in range(x.data_src.shape[0]):\n",
    "            n_source_tokens = x.data_src.shape[1]\n",
    "            for token_id in range(n_source_tokens):\n",
    "                self.src_query[batch_idx, token_id, :] = source_map[:, x.data_src[batch_idx, token_id]]\n",
    "        #source positional encoding\n",
    "        self.src_query += torch.tensor(positionalEncoding(self.seq_len))\n",
    "        self.src_query = self.dropout(self.src_query)\n",
    "        \n",
    "        self.tgt_query = torch.from_numpy(np.zeros((x.data_tgt_ip.shape[0], x.data_tgt_ip.shape[1], d_model)))\n",
    "        \n",
    "        target_map = self.target_embed.embed.weight.clone()\n",
    "        #target embedding\n",
    "        for batch_idx in range(x.data_tgt_ip.shape[0]):\n",
    "            n_target_tokens = x.data_tgt_ip.shape[1]\n",
    "            for token_id in range(n_target_tokens):\n",
    "                self.tgt_query[batch_idx, token_id, :] = target_map[:, x.data_tgt_ip[batch_idx, token_id]]\n",
    "        #target positional encoding\n",
    "        self.tgt_query += torch.tensor(positionalEncoding(self.seq_len - 1))\n",
    "        self.tgt_query = self.dropout(self.tgt_query)\n",
    "        \n",
    "        #passing through 1st encoder\n",
    "        out = self.encoder1.forward(self.src_query)\n",
    "        enc1_out = out = self.dropout(out)\n",
    "        #passing through 2nd encoder\n",
    "        out = self.encoder2.forward(out)\n",
    "        enc2_out = out = self.dropout(out)\n",
    "        #passing through 3rd encoder\n",
    "        out = self.encoder3.forward(out)\n",
    "        enc3_out = out = self.dropout(out)\n",
    "        #passing through 4th encoder\n",
    "        out = self.encoder4.forward(out)\n",
    "        enc4_out = out = self.dropout(out)\n",
    "        #passing through 5th encoder\n",
    "        out = self.encoder5.forward(out)\n",
    "        enc5_out = out = self.dropout(out)\n",
    "        #passing through 6th encoder\n",
    "        out = self.encoder6.forward(out)\n",
    "        enc6_out = out = self.dropout(out)\n",
    "        \n",
    "        #passing through 1st decoder\n",
    "        out = self.decoder1.forward(self.tgt_query, enc1_out, apply_mask=True, dec_x_msk=self.tgt_msk)\n",
    "        out = self.dropout(out)\n",
    "        #passing through 2nd decoder\n",
    "        out = self.decoder2.forward(out, enc2_out)\n",
    "        out = self.dropout(out)\n",
    "        #passing through 3rd decoder\n",
    "        out = self.decoder3.forward(out, enc3_out)\n",
    "        out = self.dropout(out)\n",
    "        #passing through 4th decoder\n",
    "        out = self.decoder4.forward(out, enc4_out)\n",
    "        out = self.dropout(out)\n",
    "        #passing through 5th decoder\n",
    "        out = self.decoder5.forward(out, enc5_out)\n",
    "        out = self.dropout(out)\n",
    "        #passing through 6th decoder\n",
    "        out = self.decoder6.forward(out, enc6_out)\n",
    "        out = self.dropout(out)\n",
    "                \n",
    "        #passing through linear layer\n",
    "        out = torch.matmul(out, target_map)\n",
    "        #print(\"transformer forward out: \", out.shape)\n",
    "        return out\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def inference(self, x):\n",
    "        \"\"\"\n",
    "        Perform inference on input in Transformer\n",
    "        Args:\n",
    "            x (torch.tensor): torch.tensor with dimension (S), where S is the sequence length including start and end token\n",
    "        Returns:\n",
    "            list: of output generated tokens\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        self.src_query = torch.from_numpy(np.zeros((1, x.shape[0], d_model)))\n",
    "        source_map = self.source_embed.embed.weight.clone()\n",
    "        #source embedding\n",
    "        for batch_idx in range(1):\n",
    "            n_source_tokens = x.shape[0]\n",
    "            for token_id in range(n_source_tokens):\n",
    "                self.src_query[batch_idx, token_id, :] = source_map[:, x[token_id]]\n",
    "        #source positional encoding\n",
    "        self.src_query += torch.tensor(positionalEncoding(x.shape[0]))\n",
    "        self.src_query = self.dropout(self.src_query)\n",
    "        \n",
    "        target_map = self.target_embed.embed.weight.clone()\n",
    "        start_token = torch.tensor([[0]], dtype=torch.long)\n",
    "        start = torch.from_numpy(np.zeros((1, 1, d_model)))\n",
    "        #target embedding\n",
    "        for batch_idx in range(1):\n",
    "            n_target_tokens = start.shape[1]\n",
    "            for token_id in range(n_target_tokens):\n",
    "                start[batch_idx, token_id, :] = target_map[:, start_token[batch_idx, token_id]]\n",
    "        #positional encoding\n",
    "        max_tokens = 50 + x.shape[0]\n",
    "        pos_encoding = torch.tensor(positionalEncoding(max_tokens))\n",
    "        \n",
    "        #passing through 1st encoder\n",
    "        out = self.encoder1.forward(self.src_query)\n",
    "        enc1_out = out = self.dropout(out)\n",
    "        #passing through 2nd encoder\n",
    "        out = self.encoder2.forward(out)\n",
    "        enc2_out = out = self.dropout(out)\n",
    "        #passing through 3rd encoder\n",
    "        out = self.encoder3.forward(out)\n",
    "        enc3_out = out = self.dropout(out)\n",
    "        #passing through 4th encoder\n",
    "        out = self.encoder4.forward(out)\n",
    "        enc4_out = out = self.dropout(out)\n",
    "        #passing through 5th encoder\n",
    "        out = self.encoder5.forward(out)\n",
    "        enc5_out = out = self.dropout(out)\n",
    "        #passing through 6th encoder\n",
    "        out = self.encoder6.forward(out)\n",
    "        enc6_out = out = self.dropout(out)\n",
    "                \n",
    "        n_generated_tokens = 0\n",
    "        preds = 0\n",
    "        pred_seq = []\n",
    "        while (preds != self.target_vocab-1) and (n_generated_tokens < max_tokens):\n",
    "            dec_ip = start\n",
    "            for i in range(dec_ip.shape[1]):\n",
    "                dec_ip[:,i,:] = dec_ip[:,i,:] + pos_encoding[i,:]\n",
    "            dec_ip = self.dropout(dec_ip)\n",
    "        \n",
    "            #print(self.tgt_query.shape, self.tgt_msk.shape, enc1_out.shape)\n",
    "            #passing through 1st decoder\n",
    "            out = self.decoder1.forward(dec_ip, enc1_out)\n",
    "            out = self.dropout(out)\n",
    "            #passing through 2nd decoder\n",
    "            out = self.decoder2.forward(out, enc2_out)\n",
    "            out = self.dropout(out)\n",
    "            #passing through 3rd decoder\n",
    "            out = self.decoder3.forward(out, enc3_out)\n",
    "            out = self.dropout(out)\n",
    "            #passing through 4th decoder\n",
    "            out = self.decoder4.forward(out, enc4_out)\n",
    "            out = self.dropout(out)\n",
    "            #passing through 5th decoder\n",
    "            out = self.decoder5.forward(out, enc5_out)\n",
    "            out = self.dropout(out)\n",
    "            #passing through 6th decoder\n",
    "            out = self.decoder6.forward(out, enc6_out)\n",
    "            out = self.dropout(out)\n",
    "\n",
    "            #passing through linear layer\n",
    "            out = torch.matmul(out, target_map)\n",
    "            #print(out.shape)\n",
    "            _, preds = torch.max(out, dim=2)\n",
    "            #print(preds)\n",
    "            #print(\"preds shape: \", preds.shape)\n",
    "            preds = preds[0, -1]\n",
    "            pred_seq.append(preds)\n",
    "            n_generated_tokens += 1\n",
    "            tmp = torch.zeros((1,n_generated_tokens+1,start.shape[2]))\n",
    "            tmp[:,:-1,:] = start\n",
    "            #print(target_map.shape)\n",
    "            #print(preds)\n",
    "            #print(tmp.shape)\n",
    "            #print(tmp[:,-1,:].shape, target_map[:, preds].T.shape)\n",
    "            tmp[0,-1,:] = target_map[:, preds].T[0]\n",
    "            start = tmp\n",
    "        #print(\"inference out: \", len(pred_seq))\n",
    "        return pred_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e7b0cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "    \"\"\"\n",
    "    generates data with \"n_data\" datapoints, each having length \"seq_len\" and the values are randomly between 1 and vocab_size\n",
    "    The start token is denoted by 0 and end token is denoted by vocab_size+1\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, seq_len, n_data):\n",
    "        self.source_vocab = vocab_size\n",
    "        self.target_vocab = vocab_size\n",
    "        self.seq_len = seq_len\n",
    "        self.n_data = n_data\n",
    "        #source input - shape (n_data, seq_len+2)\n",
    "        self.data_src = torch.from_numpy(np.random.randint(1, self.source_vocab+1, size=(self.n_data, self.seq_len+2)))\n",
    "        #start token\n",
    "        self.data_src[:, 0] = 0\n",
    "        #end token\n",
    "        self.data_src[:, -1] = self.source_vocab+1\n",
    "        #target input - shape (n_data, seq_len+1)\n",
    "        self.data_tgt_ip = self.data_src.detach()[:, :-1]\n",
    "        #target mask - shape (seq_len+1, seq_len+1)\n",
    "        self.data_tgt_msk = torch.from_numpy(np.tril(np.ones(self.seq_len+1)))\n",
    "        #target output - shape (n_data, seq_len+1)\n",
    "        self.data_tgt_op = self.data_src.detach()[:, 1:]\n",
    "        \n",
    "    def get_data(self):\n",
    "        return self.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e25ee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, test_loader):\n",
    "    \"\"\"\n",
    "    Evaluates testing data\n",
    "    Args:\n",
    "        model (__main__.Transformer): an instance of class Transformer\n",
    "        test_loader (object of class DataGenerator): Contains source data, target input data, target output data and target mask\n",
    "    Returns:\n",
    "        function call to model.testing_epoch_stats\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    batch = test_loader\n",
    "    outputs= []\n",
    "    outputs.append(model.testing_step(batch))\n",
    "    return model.testing_epoch_stats(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6815444f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(n_epoch, lr, model, train_loader, test_loader, optim_func=torch.optim.SGD, momentum=0, display_msg=False, optim_name=None):\n",
    "    \"\"\"\n",
    "    Trains the model on the given training data for \"n_epoch\" epochs \n",
    "    Args:\n",
    "        n_epoch (natural number): number of epochs\n",
    "        lr (float): learning rate\n",
    "        model (__main__.Transformer): an instance of class Transformer\n",
    "        train_loader (object of class DataGenerator): Contains source data, target input data, target output data and target mask\n",
    "        test_loader (object of class DataGenerator): Contains source data, target input data, target output data and target mask\n",
    "        optim_func (function): optimizer function. By default, torch.optim.SGD\n",
    "        momemtum (float): momentum\n",
    "        display_msg (bool): displays message if display_msg is True, by default False\n",
    "    Returns:\n",
    "        list: a list of dicts, where each dict contains training, test loss and accuracy at the end of each epoch\n",
    "    \"\"\"\n",
    "    epoch_stats = []\n",
    "    if optim_name == \"ADAM\":\n",
    "        optimizer = optim_func(params=model.parameters(), lr=lr)\n",
    "    else:\n",
    "        optimizer = optim_func(params=model.parameters(), lr=lr, momentum=momentum)\n",
    "    for epoch in range(n_epoch):\n",
    "        #Training\n",
    "        model.train()\n",
    "        batch_train_stats = []\n",
    "        \n",
    "        batch = train_loader\n",
    "        train_stats = model.training_step(batch)\n",
    "        batch_train_stats.append(train_stats)\n",
    "        train_stats[\"train_loss\"].backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "            \n",
    "        train_epoch_stats = model.training_epoch_stats(batch_train_stats)\n",
    "        \n",
    "        result = evaluate(model, test_loader)\n",
    "        result['train_loss'] = train_epoch_stats['train_loss']\n",
    "        result['train_accuracy'] = train_epoch_stats['train_accuracy']\n",
    "        if display_msg and ((epoch)%10 == 0):\n",
    "            #print(f\"Epoch [{epoch+1}/{n_epoch}], train_loss: {result['train_loss']:.4f}, train_accuracy: {100*result['train_accuracy']:.2f}%\")\n",
    "            print(f\"Epoch [{epoch+1}/{n_epoch}], train_loss: {result['train_loss']:.4f}, test_loss: {result['test_loss']:.4f}\", end=\", \")\n",
    "            print(f\"train_accuracy: {100*result['train_accuracy']:.2f}%, test_accuracy: {100*result['test_accuracy']:.2f}%\")\n",
    "        epoch_stats.append(result)\n",
    "    return epoch_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc838bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error(model_stats, optimizer_name):\n",
    "    \"\"\"\n",
    "    plots the training error and test error plots (vs) epoch \n",
    "    Args:\n",
    "        train_loss (list): list of dict containing training, test error and accuracy for each epoch\n",
    "        optimizer_name (string): optimizer used to train model\n",
    "    \"\"\"\n",
    "    plt.rcParams[\"figure.figsize\"] = (15,3)\n",
    "    plt.figure()\n",
    "    plt.subplot(121)\n",
    "    plt.title(f\"Training loss over epochs with {optimizer_name} optimizer\")\n",
    "    plt.xlabel(f\"Epoch\")\n",
    "    plt.ylabel(f\"Training loss\")\n",
    "    train_loss = [x[\"train_loss\"] for x in model_stats]\n",
    "    plt.plot(range(1, len(train_loss)+1), train_loss)\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plt.title(f\"Testing loss over epochs with {optimizer_name} optimizer\")\n",
    "    plt.xlabel(f\"Epoch\")\n",
    "    plt.ylabel(f\"Testing loss\")\n",
    "    test_loss = [x[\"test_loss\"] for x in model_stats]\n",
    "    plt.plot(range(1, len(test_loss)+1), test_loss)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99b8d6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10\n",
    "source_vocab, target_vocab = vocab_size, vocab_size\n",
    "seq_len = 8\n",
    "n_data = 100\n",
    "x_train = DataGenerator(vocab_size, seq_len, n_data)\n",
    "x_test = DataGenerator(vocab_size, seq_len, n_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c6450eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train stats: source shape torch.Size([100, 10]); target input shape torch.Size([100, 9]); target output shape torch.Size([100, 9]); target mask shape torch.Size([9, 9])\n",
      "Test stats: source shape torch.Size([100, 10]); target input shape torch.Size([100, 9]); target output shape torch.Size([100, 9]); target mask shape torch.Size([9, 9])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train stats: source shape {x_train.data_src.shape}; target input shape {x_train.data_tgt_ip.shape}; target output shape {x_train.data_tgt_op.shape}; target mask shape {x_train.data_tgt_msk.shape}\")\n",
    "print(f\"Test stats: source shape {x_test.data_src.shape}; target input shape {x_test.data_tgt_ip.shape}; target output shape {x_test.data_tgt_op.shape}; target mask shape {x_test.data_tgt_msk.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bbe14d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], train_loss: 54.2572, test_loss: 37.9904, train_accuracy: 8.33%, test_accuracy: 10.33%\n",
      "Epoch [11/200], train_loss: 27.1936, test_loss: 9.8734, train_accuracy: 11.33%, test_accuracy: 7.00%\n",
      "Epoch [21/200], train_loss: 27.2786, test_loss: 9.2706, train_accuracy: 9.89%, test_accuracy: 16.33%\n",
      "Epoch [31/200], train_loss: 24.9270, test_loss: 6.7419, train_accuracy: 11.00%, test_accuracy: 21.11%\n",
      "Epoch [41/200], train_loss: 23.4441, test_loss: 8.7524, train_accuracy: 13.78%, test_accuracy: 23.56%\n",
      "Epoch [51/200], train_loss: 22.4429, test_loss: 11.4930, train_accuracy: 17.56%, test_accuracy: 23.67%\n",
      "Epoch [61/200], train_loss: 22.2741, test_loss: 11.1991, train_accuracy: 15.22%, test_accuracy: 24.22%\n",
      "Epoch [71/200], train_loss: 21.5140, test_loss: 10.3015, train_accuracy: 15.00%, test_accuracy: 25.67%\n",
      "Epoch [81/200], train_loss: 21.1956, test_loss: 9.7270, train_accuracy: 15.33%, test_accuracy: 25.89%\n",
      "Epoch [91/200], train_loss: 20.4604, test_loss: 9.6362, train_accuracy: 15.78%, test_accuracy: 26.22%\n",
      "Epoch [101/200], train_loss: 19.3611, test_loss: 9.5505, train_accuracy: 15.67%, test_accuracy: 26.44%\n",
      "Epoch [111/200], train_loss: 20.0352, test_loss: 9.5639, train_accuracy: 15.11%, test_accuracy: 26.22%\n",
      "Epoch [121/200], train_loss: 19.0590, test_loss: 9.2944, train_accuracy: 14.78%, test_accuracy: 26.33%\n",
      "Epoch [131/200], train_loss: 18.7221, test_loss: 9.3359, train_accuracy: 17.33%, test_accuracy: 26.44%\n",
      "Epoch [141/200], train_loss: 17.9862, test_loss: 9.3567, train_accuracy: 17.89%, test_accuracy: 26.56%\n",
      "Epoch [151/200], train_loss: 18.3598, test_loss: 8.9991, train_accuracy: 16.22%, test_accuracy: 26.22%\n",
      "Epoch [161/200], train_loss: 17.7627, test_loss: 9.0652, train_accuracy: 16.33%, test_accuracy: 26.33%\n",
      "Epoch [171/200], train_loss: 16.9276, test_loss: 8.5296, train_accuracy: 17.67%, test_accuracy: 26.67%\n",
      "Epoch [181/200], train_loss: 16.4520, test_loss: 8.0555, train_accuracy: 17.11%, test_accuracy: 26.00%\n",
      "Epoch [191/200], train_loss: 16.8808, test_loss: 8.3727, train_accuracy: 17.33%, test_accuracy: 26.22%\n"
     ]
    }
   ],
   "source": [
    "optimizer_name = \"ADAM\"\n",
    "y = Transformer(vocab_size, seq_len)\n",
    "model_stats = fit(n_epoch=200, lr=1e-5, model=y, train_loader=x_train, test_loader=x_test, optim_func=torch.optim.Adam, momentum=0, display_msg=True, optim_name=optimizer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30d9657b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model parameters\n",
    "torch.save(y.state_dict(), \"first_200_epochs.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cbabc59d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_error(model_stats, optimizer_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cce4506",
   "metadata": {},
   "source": [
    "### Predicting sequence for a seen sequence in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "20ef6935",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = y.inference(x_train.data_src[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e6ffe832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output sequence length is 60\n"
     ]
    }
   ],
   "source": [
    "print(f\"Output sequence length is {len(out)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "726ed9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output sequence is [tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5)]\n"
     ]
    }
   ],
   "source": [
    "print(f\"The output sequence is {out}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ac54c0",
   "metadata": {},
   "source": [
    "### Predicting sequence for an unseen sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "935a945f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = [3,7,9,10,1,2,3,6,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7df6f041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_new_inputs(array):\n",
    "    array = [0] + array + [source_vocab+1]\n",
    "    return torch.tensor(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5bef1419",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = y.inference(process_new_inputs(sample_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "abe8ba79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output sequence length is 61\n"
     ]
    }
   ],
   "source": [
    "print(f\"Output sequence length is {len(out)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c427fc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output sequence is [tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7)]\n"
     ]
    }
   ],
   "source": [
    "print(f\"The output sequence is {out}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10164fd",
   "metadata": {},
   "source": [
    "### Observation\n",
    "Eventhough the loss is decreasing over iterations, the model is not learning the identity mapping between source and target sequence in both seen and unseen sequences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
